Hermann  Remsperger:  The  evolution  of  inflation  measurement:  a  central
banker's view
Address by Professor Hermann Remsperger, Member of the Directorate of the Deutsche Bundesbank,
at the symposium “Hedonic Methods in Price Statistics” held in Wiesbaden, 21 June 2001.
 I
Five  years  ago,  the  Boskin  Commission  reminded  us  that  inflation  measurement  is  anything  but
simple. Although experts had known many of the problems for quite a  long time, it took the Boskin
Report  to  reawaken  public  awareness.  This  forced  statistical  offices – and,  of  course,  also  central
banks – to  sit  up  and  take  note  of  the  situation  in  their  countries.  The  Boskin  Report  prompted  the
Bundesbank, too, to devote more attention again to the problems of inflation measurement.
In  the  mid-sixties,  the  Bundesbank  submitted  a  report  to  the  Federal  Fiscal  Court  in  which  the
following  opinion  was  reached:  “In  general,  it  should  not  be  considered  a  reduction  in  the  value  of
money  if  the  cost-of-living  index  rises  by,  say,  1  per  cent  per  annum;  and  an  annual  increase  of
between 1 and 2 per cent in the index can be regarded as indicating a deterioration in the value of
money only with certain reservations.” In the Bundesbank’s annual derivation of its monetary target,
this factor was reflected in a medium-term price assumption of 1½ to 2% per year.
In  1998,  our  Research  group  arrived  at  the  conclusion  that  the  range  of  uncertainty  in  measuring
inflation in western Germany is clearly below  1 per cent. There  were hardly  any thorough empirical
studies on that topic for Germany at that time. And not very much has changed in the meantime.
Yet this is exactly the reason why problems with measuring German prices will remain on our research
agenda. We certainly do not wish to take the easy way out by doctoring inflation figures downward,
nor do we wish to overstate Germany’s real economic performance. Instead, it is our duty to run reality
checks  on  statistical  methods,  and  to  analyse  their  implications  for  economic  policy  in  general  and
their importance for monetary policy in particular.
This work is also important for the calculation of real aggregates in the national accounts. In our May
2001 Monthly Report, we presented the results of a new study on this topic. It shows how real growth
would  have  developed  in  the  second  half  of  the  nineties  if  US  methods  of  calculating  the  national
accounts had been applied in Germany. The quantitative outcome of hedonic pricing and the use of
chained  indices  increased  Germany’s  statistical  growth  in  the  second  half  of  the  90’s  by  nearly
½ percentage point per annum.
We presented this result of our research together with the Federal Statistical Office to the press. And
this  is  just  but  one  indication  how  excellently  the  Federal  Statistical  Office  and  the  Deutsche
Bundesbank have been cooperating, in the field of German economic statistics in general and price
statistics in particular. And let me point out that the Bundesbank’s inflation study in 1998  would  not
have been possible without the generous support and the helpful comments given to us by members
of  the  staff  at  the  Federal  Statistical  Office.  Our  joint  sponsorship  of  this  conference,  which  is  so
brilliantly  organised  and  chaired  by  Wolfgang  Brachinger,  is  another  example  of  good  and  close
cooperation.
II
I do know, however, that central bank research papers which take a critical look at statistical methods
are not always  welcomed with  open arms  by  statistical  offices.  For  instance,  it  is  often  argued  that
studies oriented towards the ideal world of a cost-of-living index are hardly relevant to official statistics
since price statistics are founded on the principle of pure price comparisons.
I do not want to go into details of this rather fundamental discussion at this stage. However, I believe
that from an economic policy perspective it is not possible to generate a meaningful consumer price
index  without  taking  recourse  to  economic  criteria.  The  minute  one  encounters  the  problem  of
adjusting  for  quality  changes,  which  is  a  centrepiece  of  this  conference,  there  is  no  getting  around
drawing a picture of consumer assessments and consumers’ and sellers’ behaviour on the market.
BIS Review 58/2001
1
By  the  same  token,  I  don’t  think  it  would  be  desirable  to  look  for  the  perfect  “cost-of-living”  index,
meaning an index based on the sophisticated theoretical structure of microeconomics, without taking
into  account  the  feasibility  aspect.  For  all  these  reasons  it  is  necessary  to  have  an  open  dialogue
between statistical practitioners, researchers and users.
If  we  look  at  it  that  way,  price  statistics  can  never  be  static.  Some  years  ago,  Alan  Greenspan
delivered  a  speech  in  Frankfurt,  quoting  an  official  in  the  US  government  who  once  compared  a
nation's statistical system to a tailor, measuring the economy much as a tailor measures a person for a
suit – with the difference that the “person” we are measuring is running while we try to measure him.
The only way the statistical system can succeed, the US official said, is to be just as fast and twice as
flexible. That is the challenge that lies ahead, and it is, indeed, a large one.
III
Now, five years after publication of the Boskin study, we are certainly allowed to ask the following two
questions: What lessons have we actually learned? And what were the practical implications for price
statistics?
The first thing we’ve learned is that the statistical distortion which can occur at the uppermost level of
price aggregation when using a fixed basket of goods is generally quite insignificant, if the indices are
changed to new, more up-to-date baskets of goods in a timely manner. This condition is sufficiently
fulfilled for the Harmonised Index of Consumer Prices. And this is the indicator of inflation used by the
European Central Bank to define its stability target.
As for the lowest level of aggregation, Ernst Diewert has reminded us of something already preached
by Irving Fisher: We should at all costs avoid calculating the arithmetical mean of unweighted rates of
price  change.  And  that  is  exactly  the  reason,  why  the  HICP  is  based  exclusively  on  the  geometric
mean or on rates of change from average prices. So the European way of calculating the figures fulfills
a second important condition for proper price measurement.
However, a big challenge arises with the vast field of new products, new types of products and new
channels of distribution. This poses a whole set of problems for official price statistics, and it has not
yet been possible to solve them all in a fully satisfactory manner. For instance, it is hardly feasible to
take due account of new goods and new types of outlets in “real time” when measuring inflation. In the
HICP, therefore, we turn to a uniform threshold value: if the share of a new product exceeds 0.1 per
cent of total expenditure, this product should be included in the price index. It is true that this method
fails  to  capture  the  increase  in  consumer  surplus  generated  by  a  new  product  and  early  price
decreases.  However,  I  see  no  other  way  to  solve  this  problem.  Incidentally,  the  remaining
measurement bias is not likely to be very large, since fundamental product innovations tend to be rare.
All in all the just mentioned 0.1 per cent provision seems to be adequate.
The  major  problem  of  new  product  variants,  and  thus  of  adjusting  for  quality  differences  when
replacing obsolete items remains. And this is a big issue in an environment marked by rapid product
innovations. And here I do not envy the statistical offices their jobs. Our research for Germany has
shown that, in practice, even uniform quality adjustment methods lead to diverging results depending
on  the  individual  “price  collector”.  Therefore,  centralisation  of  quality  adjustment  is  the  path  often
proposed. However, this is out of reach at the European level for the time being. Another way is to
eliminate unreliable methods for quality adjustments so that the applied methods by individual “price
collectors” will on balance result in unbiased estimates of the true price change. This is how Germany
has been trying to solve the problem, and this has also been Eurostat’s method so far.
In  my  view,  the  pragmatic  approach  should  be  carried  out  very  carefully  with  all  relevant  parties
cooperating  in  a  network  of  experts.  What  I  mean  here  –  among  other  things  –  is  accompanying
research on a permanent  basis. Official methods have to be checked against potential alternatives.
Hedonic price indices should be thoroughly developed and assessed.
At the end of the conference, we may be better able to answer the question as to how far hedonics
can be used to generate indices in a timely manner. At any rate, there is much to be done regarding
quality adjustment in price statistics.
But before you go back to addressing the quality of price statistics tomorrow, it is now a pleasure for
me to invite you to test the quality of our buffet. Unlike in the use of hedonics, here “there is a free
lunch”.
2
BIS Review 58/2001
BIS Review 58/2001
3
