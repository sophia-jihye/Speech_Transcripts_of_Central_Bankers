Hermann Remsperger: Real-time data and monetary policy 
Welcome  address  by  Professor  Hermann  Remsperger,  Member  of  the  Executive  Board  of  the 
Deutsche  Bundesbank,  at  the  Bundesbank  Conference  on  “Real-time  data  and  monetary  policy”, 
Eltville, 28 May 2004. 
 Ladies and Gentlemen, 
I  have  the  pleasure  of  welcoming  you  to  our  conference  on  “Real-Time  Data  and  Monetary  Policy” 
which has been organised by Heinz Herrmann, Athanasios Orphanides and Pierre Siklos. 
Our conference concentrates on the uncertainty about the actual level of key macro variables. Until a 
few years ago, this issue received little attention in the academic debate on monetary policy. This has 
changed dramatically over the last few years, not least under the influence of economists attending 
this conference like Athanasios Orphanides or Dean Croushore. 
Awareness of the measurement problems in real-time data has important consequences. One could 
separate them into two classes which I would like to term “ex post” aspects on the one side and “ex 
ante” aspects on the other. 
With  “ex  post”  aspects,  I  mean  the  implications  for  the  empirical  analysis  of  monetary  policy.  For 
instance,  we  have  learned  that  the  evaluation  of  forecasts  based  on  final  data  may  be  misleading 
because it does not take into account which data were actually available at the time the forecasts were 
made. 
Or, as another example, when analysing monetary policy decisions, it is important to reconstruct the 
information set available to policy makers at the time the decisions were made. 
With “ex ante” aspects, I mean the implications of measurement problems for the conduct of monetary 
policy. This category includes questions like “How can we learn from past data revisions to improve 
our  knowledge  about  future  data?”  or  “How  will  the  awareness  of  these  measurement  problems 
influence our policy decisions and the choice of our monetary policy approach?”. Obviously, all these 
topics are interlinked. 
Answers to these questions require real-time data sets for key variables like real and nominal GDP, 
potential output and inflation. At first glance, developing a real-time data set seems to be rather simple 
-  just  enter  old  data  into  spreadsheets  and  save  them  for  future  use.  But  in  practice,  old  data  are 
usually overwritten by new data without saving the older vintage. 
Producing a real-time data set thus requires a substantial amount of effort, including digging through 
old source data and figuring out what data were available at what time - a Herculean task, considering 
the lack of documentation for much of the data. 
In the US, research on real-time issues owes much to the efforts of Dean Croushore and Tom Stark 
from the Federal Reserve Bank of Philadelphia who developed a comprehensive real-time data set for 
the  US  economy.  At  the  same  time,  Athanasios  Orphanides  reconstructed  the  real-time  data  and 
forecasts  available  to  the FOMC  from  the  Greenbooks which  are  prepared  by  the  Federal Reserve 
staff for each meeting. 
The  pioneering  work  of  our  American  collegues  has  shown  that  measurement  problems  do  indeed 
matter for the conduct of monetary policy. For example, we have learned from their studies that the 
problem of measurement error is likely to be particularly severe for the output gap - a concept which 
figures very prominently in much of the recent literature on monetary policy issues. 
Thus, it is not surprising that researchers outside the US, in particular in Europe, have taken up the 
issue  of  real-time  data.  This  conference  here  in  Eltville  offers  a  good  chance  to  present  recent 
research  on  this  issue.  Today  and  tomorrow,  we  will  listen  to  presentations  of  papers  based  on 
real-time national data for the US, the UK, Germany, Japan, Canada, Norway and Switzerland as well 
as realtime OECD forecasts for the G7 countries and the euro area countries. 
We at the Bundesbank started to compile a set of real-time data on the German economy two and a 
half  years  ago.  And  we  have  used  these  data  for  selected  research  topics.  Let  me  give  you  three 
examples. 
BIS Review 33/2004 
 1
First, Jörg Döpke has used the data set to calculate real-time output gaps (Discussion Paper 11/2004). 
In  accordance  with  the  studies  by  Orphanides  and  van  Norden  (1999,  2002),  he  finds  that  the 
real-time gaps differ considerably from their counterparts based on the latest vintage of data. 
One period when the difference between today’s estimates and the real-time perception of the output 
gap was particularly pronounced is the economic boom following German reunification. At that time, 
the measurement error for the output gap reached a size of up to four percentage points (depending 
on the estimation method used). 
In this particular case, the error was due to a temporary underestimation of actual output as well as to 
a more persistent overestimation of potential output. Doepke’s results thus provide additional evidence 
that measurement problems can seriously distort the assessment of current economic activity relative 
to its long-run trend. 
Second, Thomas Knetsch has analysed the importance of inventory investment for German business 
cycles. He finds that preliminary national accounts data of inventory investment are generally of poor 
quality. In another paper, he discusses how additional real-time information, in particular data from the 
Ifo Business survey, can be used to improve upon the preliminary official figures on the current level of 
inventories (Discussion Paper nine and 10/2004). 
Third,  Christina  Gerberding,  Franz  Seitz  and  Andreas  Worms  have  used  the  real-time  data  set  to 
re-examine the existing “evidence” that the Bundesbank’s monetary policy can well be captured by a 
standard  Taylor  rule.  As  you  know,  Clarida,  Gali  and  Gertler  claimed  to  have  shown  that  the 
Bundesbank did not pursue a strategy of monetary targeting but in effect followed a forward-looking 
variant of the Taylor rule. 
I do not wish to anticipate the discussion at our conference. But I’m sure that we will hear some new 
arguments about monetary policy in Germany in the past. For instance, Gerberding, Seitz and Worms 
will present evidence that the Bundesbank did respond to deviations of real-time measures of money 
growth, expected inflation and output growth from their respective targets. 
In my view, the debate about the Bundesbank’s monetary policy directly leads to the “ex ante” aspects 
of  data  uncertainty,  and  thus  to  the  following  question:  How  should  central  bankers  deal  with 
measurement problems and other forms of data uncertainty during the decision-making process? I’d 
like to make four short remarks on that question. 
First  of  all,  it  seems  fairly  uncontroversial  to  me  that  concern  about  data  uncertainty  provides  an 
additional and important argument against fine-tuning the economy with monetary policy instruments. 
We have to take into account that data on current output are exposed to considerable uncertainty. On 
top of that, it is even more difficult to estimate potential output. Hence, every attempt to fine-tune the 
economy bears the risk of policy errors with the corresponding negative effects on price stability. 
In my view, and that’s my second point, the more recent research on data uncertainty supports the 
principle of a cautious monetary policy approach (“steady as she goes policy”). 
As  we  know  that  important  data  on  the  economic  situation  are  subject  to  revision,  it  generally  can 
make  sense  to  wait  for  newer,  and  more  reliable,  data.  Cautious  central  bankers  only  change  the 
status  quo  in  monetary  policy  when  the  signs  of  an  assumed  change  in  the  development  of  key 
macroeconomic variables become more apparent. 
The  problem  of  data  uncertainty  suggests  that  we should  not  rely  on  one  single  indicator when  we 
have  to  assess  risks  to  price  stability.  Instead  we  should  analyse  a  broad  range  of  information 
variables.  However,  when  following  such  a  broad  approach,  we  have  to  take  into  account  that  the 
extent of measurement problems differs from one indicator to the other. 
Very  generally  speaking,  and  that’s  my  third  point,  I’d  like  to  emphasise  that  indicators  from  the 
monetary  and  financial  sphere  are  far  less  affected  by  the  problem  of  data  uncertainty  than  real 
economic variables such as output and the output gap. 
Against this background, it comes as no surprise that a monetary policy approach should be as robust 
as possible against different forms of data and model uncertainties. 
In the past few years, a number of simulation studies have been carried out to assess which monetary 
policy  approach  achieves  good  results  under  various  assumptions  about  the  transmission  process. 
These  studies  take  into  account  model  uncertainty.  However,  they  largely  disregard  the  problem  of 
data uncertainty. Consequently, their value for practical monetary policy is rather limited. 
2 
 BIS Review 33/2004
I think, the search for a robust strategy in monetary policy could be broadened to include the kind of 
measurement problems that we will discuss here at this conference. Taking this broader perspective, 
and that’s my fourth and final point, a monetary policy would be considered robust if it performed well 
in the face of different forms of data and model uncertainty. Research in this direction has only just 
begun.1 I hope that this research will give further support to the ECB’s strategy. 
Let me conclude by emphasising that research on real-time data is of utmost importance for central 
banks.  That’s  why  I  am  very  much  interested  in  the  papers  that  you  will  present  here  today  and 
tomorrow. I wish you thought-provoking discussions and a pleasant stay at our conference facilities. 
Thank you very much for your attention. 
                                                      
1   See,  for  instance,  Walsh,  C  (2003):  “Implications  of  a  changing  economic  structure  for  the  strategy  of  monetary  policy”, 
Federal Reserve Bank of Kansas City”. 
BIS Review 33/2004 
 3
