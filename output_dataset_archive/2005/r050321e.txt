Rachel Lomax: Inflation targeting in practice - models, forecasts and hunches 
Speech  by  Ms  Rachel  Lomax,  Deputy  Governor  of  the  Bank  of  England,  to  the  59th  International 
Atlantic Economic Conference, London, 12 March 2005. 
I am most grateful to Jens Larsen, James Bell, Fabrizio Zampolli and Robin Windle for research support; and to Charlie Bean, 
Peter Andrews, Spencer Dale, Phil Evans, Laura Piscitelli and other colleagues at the Bank of England for helpful comments. 
 Introduction 
Five  and  a  half  years  ago  in  his  Monnet  lecture  Charles  Goodhart1  was  able  to  talk  with  some 
confidence  of  the  features  that  particularly  distinguished  the  UK’s  approach  to  inflation  targeting. 
Today with over 20 countries, in every habitable continent, formally operating some variant of inflation 
targeting and many more adopting some parts of the framework, all actively sharing experience and 
best practice, I suspect that most aspects of our approach would find a counterpart somewhere else in 
the world. But Charles’s focus on the Monetary Policy Committee’s (MPC) personal engagement in 
producing a published inflation forecast still seems to me to capture the essence of the UK’s approach. 
Today I want to talk about the role that forecasting has come to play in helping the MPC to take and 
communicate its decisions. In what sense does the Committee really ‘own’ the published forecasts that 
go out under its name? How much use do we make of models, and what models do we use? How far 
do  our  forecasts  appear  to  drive  interest  rate  decisions?  And  is  there  any  evidence  that  this  has 
helped to make policy more or less predictable? Finally I want to end by commenting on some of the 
issues raised by forecasts as a means of communication. 
Why the MPC has always been involved in forecasting 
The MPC’s early involvement in the forecast process is firmly rooted in the kind of committee it is, as 
well as the nature of the remit it has been given. 
The objectives of UK monetary policy have been expressed in terms of an annual inflation target since 
1992,  but  responsibility  for  achieving  the  target  initially  lay  with  the  Treasury,  acting  on  the  Bank’s 
advice. In 1997, as part of a wide ranging restructuring of the Bank of England’s role, decisions about 
interest rates were delegated to the Bank’s new MPC. Its nine members – five internal Bank officials 
and four external members chosen for their relevant knowledge and experience – are individually, and 
publicly, accountable for meeting the inflation target.   
The  Government  remains  responsible  for  setting  the  annual  inflation  target,  within  the  context  of 
legislation that requires the Bank of England to achieve ‘price stability and subject to that to support 
the government’s objectives for output and employment’. Under its current remit, the MPC is required 
to achieve 2% consumer price inflation ‘at all times’. If inflation deviates from target by more than 1 
percentage point, the MPC has to write a public letter to the Chancellor to explain why, and what it is 
doing to bring it back.   
These arrangements remain relatively novel and unusual in UK constitutional terms. Prior to 1997, a 
longstanding objection to Bank of England independence was concern that such arrangements would 
be inconsistent with Ministerial duty to answer to the House of Commons on major matters of policy. A 
high level of transparency and openness about MPC decisions has been a critical aspect of meeting 
expectations of parliamentary and public accountability as well as an effective way of enhancing the 
credibility of monetary policy.  
In fact greater openness about monetary policy was part of the package of changes that were made to 
restore credibility after the UK’s exit from the ERM in 1992. The Bank played its part by introducing a 
new  quarterly  Inflation  Report,  which  by  1997  had  won  widespread  respect  for  its  objectivity  and 
                                                      
1   Goodhart, C (1999) ‘Recent developments in central banking: some special features of the Monetary Policy Committee and 
of the European system of central Banks’ Jean Monnet Lecture, Dublin European Institute, 1999. 
BIS Review 17/2005 
 1
professionalism. Against this background, the 1998 Bank of England Act required the new Monetary 
Policy Committee to sign off the Bank’s Inflation Report. In practice, the MPC’s sign off has been far 
from a formality, though the Inflation Report formally remains the Bank’s report. 
It is not that surprising that a committee of experts whose external members are based in the Bank 
and who devote at least 60% of their time to monetary policy should get deeply involved in preparing 
and  debating  the  forecasts  that  they  sign  off.  It  may  be  more  remarkable  that  nine  economists, 
labouring  under  the  burden  of  individual  accountability,  have  so  far  succeeded  in  signing  off  31 
editions of the Inflation Report, and found ways of dealing with the inevitable range of views.  
The nature and role of the forecast 
Nowadays  the  forecast  has  two  related  roles  in  the  monetary  policy  process.    First,  it  helps  the 
Committee to set monetary policy by organising, informing and focusing its discussions.  And second, 
it  provides  transparency  about  the  Committee’s  thinking  and  plays  a  key  part  of  its  public 
communication strategy.2 
Helping the MPC make decisions 
Monetary  policy  needs  to  be  forward  looking,  because  interest  rates  act  with  a  lag.    No  monetary 
policymaker can avoid taking a view on the future.  That view needs to be coherent and disciplined, 
and informed by the best information available. But it also needs to reflect a realistic appreciation of 
the massive uncertainties inherent in any forecast.  
The MPC spends many hours discussing the projections that go into the Inflation Report and the text 
that accompanies them. Although the process has been somewhat streamlined since Charles’s day 
(when  the  committee  spent  a  gruelling  ten  meetings  a  quarter  on  the  forecast  on  top  of  the  usual 
monthly decision meetings) the forecast round is probably still the largest single commitment of the 
Committee’s time.  
Why? An important reason is that the forecast is not just an occasion for agreeing a set of projections 
for the inflation outlook. It has come to provide an organising framework for assessing all the relevant 
information, and an opportunity for a deeper discussion of economic developments. Since I have been 
on  the  Committee,  we  have  spent  at  least  half  our  allotted  forecasting  time  debating  longer  term 
issues,  such  as  the  effect  of  structural  change  in  the  labour  market  and  the  relationship  between 
house  price  inflation  and  consumption.  Sometimes  the  outcome  of  those  discussions  has  had  a 
material influence on our thinking about risks, even when the direct impact on the central projections 
has been relatively minor.  
What role do formal economic models play in the forecast? No set of economic projections – least of 
all one owned by a committee of nine experts – can ever be the outcome of a purely model-based 
operation. Judgement always plays a large role – although different people frame their judgements in 
more  or  less  model-based  ways.  But  it  is  difficult  to  make  a  forecast  without  using  models:  they 
provide  an  organising  framework  for  ensuring  intellectual  and  accounting  consistency  in  generating 
baseline projections, and for considering alternative scenarios and risks.  
What sorts of models does the Committee find useful? 
In  his peer  review  of  the Bank’s  use of  economic models3,  Adrian  Pagan suggested  that economic 
modelling  may  involve  a  trade  off  between  theoretical  consistency  (good  economics)  and  data 
coherence (a good fit); our goal should be to ensure that we are positioned on the efficient frontier 
between the two.  
Any model we use should in principle be on this frontier – but we want to be able to move along the 
frontier and use different sorts of models for different purposes. 
                                                      
2   Charles gives five arguments for having an IR that is the responsibility of the MPC itself: transparency, discipline, a better 
informed MPC, better forecasts and accountability (in that order). I think they fit within my taxonomy. 
3   Pagan,  A  (2003)  ‘Modelling  and  forecasting  at  the  Bank  of  England’,  Bank  of  England  Quarterly  Bulletin  Spring  2003.   
Adrian  Pagan  has  been  commissioned  to  produce  a  postscript,  following  the  introduction  of  the  new  Bank  of  England 
Quarterly Model.   This will be published later this year. 
2 
 BIS Review 17/2005
For  example,  if,  as  I  have  suggested,  we  want  to  use  models  to  facilitate  discussions  about 
fundamental economic issues, we clearly need models with rich economic structures – structures that 
reflect  the  Committee’s  views  on  the  way  the  economy  works.    The  Bank’s  new  Quarterly  Model 
(BEQM)4 has been developed with this function very much in mind. But we also use other and smaller 
models with rich economic structures to look at specific issues as part of our suite of models. 
We also want to quantify the likely impacts on inflation and output of a range of pieces of data news as 
accurately  as  possible.    The  numbers  matter,  so  empirical  performance  is  important,  too.  We  have 
worked hard at ensuring that BEQM does well in this dimension, but we have also, within our suite, 
been developing more statistically based models.  We may use these models on their own – as stand 
alone forecasting tools – or to inform the judgements that we make in using BEQM. 
Let me say a few words about both the main model and the suite.  
The motivation for the BEQM project was to help with the ‘intellectual framework’ role of the forecast.  
Without  losing  empirical  performance,  we  wanted  to  improve  upon  the  previous  main  model’s 
articulation of the underlying structure of the economy, to make it more explicitly consistent with the 
Committee’s  beliefs.5    This  was  made  possible  in  the  light  of  recent  advances  both  in  economic 
understanding – particularly the emphasis on providing coherent micro foundations in macroeconomic 
models – and in sheer computational power (both in terms of computing power and the techniques 
applied).  
BEQM  is  a  large  scale  model  by  the  standards  of  most  academic  research,  but  it  is  small  scale 
compared with traditional macro-econometric models. Compared with the latter, it is also more of a 
general equilibrium model with an emphasis on internal consistency.  Households and firms optimise – 
they are forward-looking and they use   available information efficiently. Unlike our previous model, 
things  add  up:  flows  add  to  stocks,  profits  are  allocated,  and  so  on.    There  is  a  high  degree  of 
simultaneity in the way the model is solved. It no longer makes sense, nor is it at all easy, to consider 
the model equation by equation.   
This provides a greater degree of discipline on Committee members and staff, who are now forced to 
confront the full implications of their judgements more explicitly.  If someone wants to change one of 
the economic relationships, they need to say why, and acknowledge the possible implications for other 
behavioural relationships.  If, for example, we want to assume that the trend rate of labour productivity 
growth has changed, the model requires us to recognise that there are implications for both demand 
and  supply.    Faster  productivity  growth  will  increase  productive  capacity,  but  income  will  also  grow 
faster. So what might that mean for demand now?  
This is a definite advance – providing the general equilibrium mechanisms in the new model do in fact 
reflect  our  ideas  about  how  the  world  works.    But  it  also  makes  for  a  more  demanding  discussion. 
There  are  no  easy  fixes,  and  it  can  be  difficult  to  accommodate  views  that  differ  from  the  model’s 
paradigm.  As an example, the model is firmly rooted in the rational expectations tradition.  And we 
have  assumed  that  monetary  policy  is  credible.    Both  are  perfectly  reasonable,  arguably  essential, 
modelling assumptions.  The fact that the new model makes them explicit can be intellectually helpful. 
But it doesn’t make it any easier to provide answers to questions about expectations and credibility.  
What if some agents base their decisions on simple rules of thumb?  BEQM has features that allow us 
to accommodate such questions when we are forecasting – but in a more ad-hoc way that requires a 
substantial degree of judgement.  
We are still learning how to exploit all BEQM’s possibilities. But it clearly represents a move towards 
the  ‘Pagan  frontier’,  offering  a  higher  degree  of  theoretical  coherence  without  losing  empirical 
performance.    A  number  of  other  central  banks  are  working  on  similar  models  –  the  ECB,  Bank  of 
Canada, FRB, Norges Bank and Bank of Finland – as well as the IMF.  The international modelling 
community is an exemplary forum for the exchange of ideas and experiences, and we have learnt – 
and will continue to learn – a lot from the experience of others.  
No model can do everything. All models oversimplify drastically. The trick is to identify an appropriate 
degree of simplification for the task in hand. So the Committee has never been prepared to rely on one 
model. This has led to attempts to develop a suite of models. 
                                                      
4   Harrison, R, Nikolov, K, Quinn, M, Ramsay, G, Scott, A and Thomas, R (2005) The Bank of England Quarterly Model. 
5   For a description of the previous model, see Economic Models at the Bank of England (1999). 
BIS Review 17/2005 
 3
The suite takes two forms. 
One is a range of models that are complementary to the core forecasting model.  These hold up a 
magnifying glass to particular parts of the economy, and allow us to take account of the influence of a 
wider range of factors in more detail than could be accommodated in the main model.  These (sub-) 
models might be geared towards analysing particular policy issues (e.g., supply chain pricing models, 
the  future  development  of  household  and  corporate  gearing,  productivity  growth  in  the  distribution 
sector).  Or they might also provide the interface between our very short-term conjunctural analysis, 
and the 2-3 year forecast.   
Second,  we  have  a  set  of  statistical  models.  The  MPC  attempts  to  process  a  huge  amount  of 
information before each monthly decision. The Committee already uses some data-driven forecasts 
(for example, forecasts that uses many variables to forecast in an a-theoretic way, statistical models to 
produce near term forecasts for key data such as CPI, and small models that filter ONS first releases, 
to handle the inevitable data uncertainty associated with early releases6).  But it is a herculean task to 
absorb and analyse all the data. So, responding to the needs of the MPC, but also to suggestions by 
Pagan, the staff is in the process of developing and evaluating more models geared towards empirical 
forecasting  accuracy  and  finding  ways  of  combining  these  forecasts  in  a  statistically  efficient  way.  
This is very much work in progress, with the aim of helping the MPC to form judgements both about 
the most likely outturns and the uncertainty surrounding them.  
Handling uncertainty and disagreement 
Even armed with a range of economic models to aid structured discussion and enforce a degree of 
intellectual  discipline,  how  is  it  possible  for  a  group  of  nine  individually  accountable  economists  to 
reach sufficient agreement to publish a forecast which is described as reflecting their best collective 
judgement? 
An important part of the answer lies in the use of formal techniques to capture uncertainty and risk. 
These  antedate  the  MPC.    The  Bank  of  England  started  publishing  fan  charts  for  its  inflation 
projections  in  February  1996,  following  an  early  experiment  with  what  might  be  called  ‘trumpet 
charts’.7  The motivation  was  purely  to  illustrate  the uncertainty  inherent  in  all economic  projections. 
While  trumpets  consisted  of  a  single  shaded  area  around  a  central  projection,  corresponding  to 
average absolute forecast errors (see Chart 1), fan charts (see Chart 2) were graduated to show the 
full distribution of possible outcomes.8   
Chart  1. 
  November  1995  RPIX 
projection – symmetric error bands 
Chart  2.  February  1996  RPIX 
projection – fan chart 
inflation 
inflation 
                                                      
6   Ashley, J, Driver, R, Hayes S and Jeffrey, C (2005) ‘Dealing with data uncertainty’ Bank of England Quarterly Bulletin 
Winter 2005, published on 14 March 2005. 
I am indebted to Mark Allan and James Bell for this nice descriptor. 
7  
8   For a further description of the fan chart methodology, see Inflation Report May 2002 p 48-49 and Britton, E, Fisher, P and 
Whitley,  J  (1998)  ‘The  Inflation  Report  projections:  understanding  the  fan  chart’  Bank  of  England  Quarterly  Bulletin 
February 1998. 
4 
 BIS Review 17/2005
Nowadays,  each  Inflation  Report  includes  fan  charts  for  inflation  and  output  which  reflect  the 
Committee’s views on the full distribution of possible outcomes.  While the width of the fan bears some 
relation  to  the  size  of  forecast  errors  over  the  past  decade  (the  distribution  of  past  forecast  errors 
provide  a  benchmark  calibration),  its  main  features  –  the  moments  of  the  underlying  distribution  – 
change  with  each  forecast  to  reflect  the  Committee’s  best  judgement  about  the  balance  of  risks 
around  the outlook  for  inflation  and  output  and  the degree  of  uncertainty.  While  many  other central 
banks now publish fan charts, the MPC is still relatively unusual in basing them on the policymakers’ 
subjective view about the distribution of risks, rather than staff views or historical/statistical measures 
of past errors. 
The MPC’s approach to constructing fan charts can help the members come to an agreement on the 
substantive issues, while retaining their individual views. This is because the risks are often where the 
major differences of opinion amongst members lie.  And while the members may be able to agree on a 
collective view of the overall outlook including the degree of uncertainty and balance of risks, it might 
be for slightly different reasons.  To be sure, there have been times when differences of view about the 
central  projection  have  been  too  significant  to  be  handled  within  the  ambit  of  the  fan  chart  and  on 
those (few) occasions the Inflation Report has included material illustrating the minority view. But, as 
the MPC’s preface to the Inflation Report notes, the fan charts reflect the Committee’s best collective 
judgement about the most likely paths for output and inflation and the uncertainties surrounding the 
central  projections,  while  recognising  that  members  may  have  slightly  different  views  about  the 
underlying assumptions.  
Forecasts and interest rate decisions 
How  influential  is  the  forecasting  process  when  it  comes  to  the  actual  business  of  taking  decisions 
about interest rates?  
One yardstick might be whether the MPC is more likely to change rates in Inflation Report months.  
There is no necessary reason why this should be so: information accrues relatively evenly over the 
year, and the Committee goes through the same decision taking process every month. On the other 
hand, the MPC might be more likely to change rates after a systematic and full review of the inflation 
outlook, rather than in response to the news on the month.  On this argument, ready-reckoners may 
give a rough indication of what the impact of new data may be, but they are no substitute for a full 
analysis.  So in non-Inflation Report months the MPC may sometimes decide to ‘wait-and-see’ – to 
postpone a possible interest rate change until more evidence has accumulated.  
As it happens, market economists have tended to think that interest rate changes were more likely in 
Inflation Report months. Since 1998, Reuters have asked a group of economists (initially around 20-
30, now 40 or more) to attach probabilities to a range of different outcomes for interest rates, so we 
can calculate a mean and a mode expected interest rate change across individuals.  Panel B in Chart 
3  split  the  months  in  which  the  mode  is  for  a  (25bp)  change  into  Inflation  Report  and  non-Inflation 
Report  months.    According  to  this  measure,  markets  have  consistently  thought  that  changes  were 
more likely in Inflation Report months.  
The data on interest rate changes provide mixed evidence. Over the period since 1997 as a whole, the 
Committee has displayed a preference for changing rates in Inflation Report months. But it showed no 
such  tendency  in  its  early  years.  The  picture  since  2001  is  very  different,  with  almost  two  thirds  of 
rates  changes  taking  place  in  Inflation  Report  months,  compared  with  the  one  third  that  would  be 
expected if rate changes were evenly spread over the year. And no fewer than six of the last eight rate 
changes  have  coincided  with  the  publication  of  an  Inflation  Report.  (See  Chart  3  and  Table  2  for 
details). 
BIS Review 17/2005 
 5
 
Chart  3.    Proportion  of  actual  and  expected  interest  rate  changes  occurring  in  Inflation  Report 
months. 
(A) Actual changes 
(B) Expected changes 
Percentage of interest rate changes
100
90
80
70
60
50
40
30
20
10
0
one-third
Percentage of interest rate changes
100
90
80
70
60
50
40
30
20
10
0
one-third
1997-2000
2001-present
IR months
whole period
Not IR months
1997-2000
2001-present
IR months
whole period
Not IR months
  
What – if anything – should be read into the MPCs apparent change in behaviour? On the face of it, 
the  evidence  might  suggest  that  the  re-evaluation  of  the  outlook  undertaken  during  the  quarterly 
forecast has become more influential. But there are a number of possible explanations.  
Most obviously, it could be a reflection of the shocks that have come along in the last 4 years. These 
may  have  required  fewer  changes  in  the  policy  rate  than  in  the  pre-2001  period.    Alternatively,  the 
required  adjustments  in  rates  might  have  been  bigger  in  the  early  days,  and  if  the  MPC  had  an 
inclination  to  change  rates  in  small  steps,  perhaps  because  it  had  good  reasons  for  proceeding 
cautiously,  then  larger  desired  adjustments  might  have  required  more  frequent  changes:  of  the  16 
changes  in  the  first  period,  7  were  back-to-back,  while  in  the  second  period,  only  4  out  of  the  14 
changes happened in consecutive meetings.  
The turnover in the Committee’s membership since 2000 might provide a different kind of explanation. 
The present Committee contains only one member (the present Governor) who has been there from 
the outset, and some of the early members served short terms. Might the latter day tendency towards 
changing rates only after a forecast reflect a generally less activist approach to setting rates?  
Table 1 provides an unscientific guide to Committee members’ degree of activism:  it is arranged with 
the  most  ‘activist  members’  (identified  as  those  voting  proportionately  most  frequently  for  a  rate 
change)  at  the  top.9    If  personal  preferences  played no  role,  we might  expect  to  see  a  relationship 
between  activism  and  ‘MPC  vintage’  –  if  MPC  members  responded  to  the  same  shocks,  or  their 
behaviour was affected by some other common factor, there would be clusters.  Keen MPC watchers 
will no doubt find some support for the view that personality matters.  But, in general, the members 
who  voted  for  the  most  rate  changes  are  associated  with  the  earlier  years  of  the  Committee, 
consistent  with  the  idea  that  the  MPC  may  have  needed  to  respond  more  frequently  during  that 
period.10   
                                                      
9   We  have  excluded  the  first  7  months  of  the  MPC’s  existence  to  allow  for  the  possibility  that  the  first  rate  changes  were 
reflecting necessary adjustments to reach what the MPC thought was the right level of interest rates. 
10   There are, of course, also other possible explanations, e.g. if a member has views which are consistently adrift of the rest of 
the  Committee,  leading  them  to  believe  that  rates  are  significantly  too  low/high,  then  they  may  repeatedly  –  and 
unsuccessfully – vote for a change without being ‘activist’ in the sense of wanting to change rates frequently in response to 
news.    
6 
 BIS Review 17/2005
Table 1: MPC members’ voting statistics from January 1998 (current members in red)1 
 
 
%  of  months 
voted  for  a  rate 
change 
%  of  changes  voted 
for  that  were  in  IR 
months 
of 
Number 
meetings 
attended since 
Jan 1998 
Time of membership 
 
29 
17 
28 
29 
37 
37 
41 
58 
87 
57 
54 
29 
46 
67 
21 
32 
54 
20 
33 
 
79 
65 
61 
52 
51 
49 
46 
41 
39 
37 
33 
34 
33 
30 
29 
28 
28 
25 
24 
 
1997-2000 
1997-1999 
1998-2000 
1997-2000 
1999-2002 
2000-2003 
1997-2001 
2000-date 
1997-date 
1997-2002 
1997-2002 
2002-date 
2001-date 
1997-2003 
2003-date 
2002-date 
2000-date 
2003-date 
2002-date 
 
 
Willem Buiter 
36 
Sir Alan Budd 
30 
John Vickers 
29 
Charles Goodhart 
36 
Sushil Wadhwani 
37 
Christopher Allsopp 
44 
DeAnne Julius 
47 
Stephen Nickell 
50 
Mervyn King 
41 
David Clementi 
43 
Ian Plenderleith 
44 
Sir Andrew Large 
40 
Kate Barker 
53 
Sir Edward George 
45 
Richard Lambert 
67 
Marian Bell 
56 
Charles Bean 
60 
Rachel Lomax 
80 
Paul Tucker 
63 
1 Up to and including the February 2005 MPC meeting. 
 
Has the publication of regular forecasts, which are seen to bear a close relationship to the decision 
taking process, helped to make the policy decisions themselves more predictable? The test is whether 
markets are less likely to be surprised by interest rate changes, given full knowledge of all the relevant 
economic news.   
We  ran  some  simple  statistical  tests  on  two  measures  of  ‘market  surprises’.    One  is  based  on  the 
Reuters  poll  of  economists.    The  surprise  measure  is  the  difference  between  the  actual  repo  rate 
change  and  the  mean  expected  repo  rate  change.    The  other  surprise  measure  is  a  bit  further  out 
along the yield curve: changes in the implied three-month forward LIBOR rate.11    
Both measures suggest that interest rate surprises have become significantly smaller in the post-2001 
period  than  previously  (Table  2  Panel  C),  consistent  with  improved  policy  predictability.      But, 
intriguingly, there is also some tentative evidence that surprises in Inflation Report months tend to be 
relatively large.12  What are we to make of that? 
                                                      
11   More precisely, this is an implied 3-month Libor forward rate at a constant horizon of 3-months, where the constant horizon 
is calculated by  linear interpolation of adjacent futures contracts.  The results are largely invariant to using six or twelve 
month horizons.  
12   This could, of course, be entirely driven by the expectation that there would be no move in non-Inflation Report months: in 
the extreme, if the distribution of surprises in those months is degenerate (i.e. so that no one expected a change in rate and 
this was what actually happened) then the statement that surprises are bigger in Inflation Report months is no different from 
the  statement  that  rates  are  only  expected  to  change  in  these  months.    The  closer  the  distribution  comes  to  being 
degenerate, the more weight should be attached to that interpretation.  But both the average surprise and its variance are 
significant.  
BIS Review 17/2005 
 7
On closer inspection, this finding seems to relate to the decision in Inflation Report months – not the 
publication of the Report itself a week later, or the minutes the week after that (Panel E shows that the 
market  reaction  to  the  policy  decision  is,  on  average,  significantly  bigger  than  the  reaction  to  the 
Report and the minutes).  This might imply that it is the rethink during the preparation of the Inflation 
Report that counts. But, once announced, the decision itself (and the accompanying press notice, if 
rates  have  changed)  provides  most  of  the  information  the  market  needs  to  understand  the 
Committee’s approach.  This would be consistent with a fairly high degree of policy predictability. 
It  is  worth  emphasising  that  the  observed  tendency  for  interest  rate  changes  to  coincide  with  the 
publication of an Inflation Report does not imply that interest rate changes are tied in any mechanical 
way  to  the  central  projection  for  inflation.    The  assessment  of  risks  is  always  a  material  factor  in 
determining policy, as well as an important aspect of the presentation of the forecast. For example in 
our latest Inflation Report we published a central projection which showed inflation rising gently but 
steadily above the 2% target, assuming a nearly flat profile of interest rates out to three years. But the 
Report noted that the balance of risks was to the downside and singled out some key near term risk 
areas, such as the household sector.  This provided a nuanced background to the MPC’s February 
decision to hold rates unchanged.  
Forecasts and public communication 
All  inflation  targeting  central  banks  use  their  forecasts  as  a  communication  tool.    They  provide  a 
coherent  statement  of  policymakers’  thinking  about  the  economic  outlook  and  the  policy  stance. 
Together with the minutes of the policy meetings (in our case published with individual votes after two 
weeks), this helps to discharge the Committee’s democratic duty to explain itself, as well as supporting 
its credibility and helping to anchor inflation expectations.13 The Inflation Report plays a central role in 
the Committee’s communication.  Since August 2003 the Governor has fronted the regular Inflation 
Report press conference, and the MPC’s appearances in front of the Treasury Select Committee has 
been (loosely) linked to the Inflation Report cycle.  
This brings me to a much debated question: how much information should a central bank provide?  
Academics  have  tended  to  press  the  case  for  more  transparency,  while  practicing  central  bankers 
have been more cautious, (though much more predisposed to openness than they would have been 
twenty years ago). Don Kohn14 argues that “more is not necessarily always better, and at each step of 
the way central banks have needed to take account of the potential costs as well as the benefits of 
greater transparency”.  In particular it is argued that the publication of some kinds of information could 
make it more difficult for policymakers to do their job, with discussions of the possible path of future 
interest rates being seen as particularly hazardous, if they appear “as a firmer pre commitment than 
they were intended to be”.15   
Arguably these should not be a first order issues for central banks with a transparent inflation targeting 
framework.  The  objectives  of  policy  are  clear,  and  outside  commentators  should  have  access  to 
enough information to work out the future direction of rates for themselves. Nevertheless there has 
been  a  closely  related  debate  about  how  transparent  an  inflation  targeting  central  bank  should  be 
about the interest rates on which its forecasts are based.  An obvious reason for wanting more direct 
information  about  the  ‘preferred’  path  is  to  get  direct  evidence  on  the  interest  rate  strategy.  (How 
quickly will rates rise? What are the advantages of a ‘wait-and-see’ approach?) 
                                                      
13   As Mishkin puts it ‘.[H]aving secretive central banks is inherently undemocratic…[B]asic democratic principles require that 
the central bank be accountable for its actions: this requires that the public understands what the central bank is doing. In 
addition, democratic principles indicate that the preferences of policymakers need to be aligned with those of the society at 
large.’  Mishkin,  F  (2004)  ‘Can  central  bank  transparency  go  too  far?’  in  Kent,  C  and  Guttman,  S  (eds.)  The  future  of 
inflation targeting Reserve Bank of Australia.  
14   Kohn, D (2005)  ‘Central Bank Communication’.  Remarks at the Annual Meeting of the American Economic Association 
January 2005. 
15   Mishkin has sympathy for this view, noting that “[w]hen new information comes in and the central bank changes the policy 
rate from its projected path, the public may see this as reneging on its announced policy or an indication that the central 
bank's previous policy settings  were a mistake.   Thus, even  when the central bank is conducting its policy in an  optimal 
manner,  deviations  from  its  projected  path  may  be  viewed  as  a  central  bank  failure  and  could  hurt  the  central  bank's 
credibility.”  
8 
 BIS Review 17/2005
The  MPC  has  long  published  forecasts  on  two  different  interest  rate  assumptions.    On  one  –  the 
constant rate assumption – interest rates are held constant over the entire forecast horizon.  On the 
other, interest rates evolve in line with rates expected by financial markets.  Until August 2004, the 
presentation emphasised the forecast based on constant rates. Since last August we have reversed 
the presentation, to emphasise the market rate assumption.16   
The constant interest rate path is obviously a stylised assumption, which conveys limited information 
about future policy intentions.  The message is that the MPC makes interest rate decisions one at a 
time, and that it has not made up its mind about what future path of rates will be consistent with the 
inflation  target.  The  market  interest  rate  path  too  is  a  conditioning  assumption,  not  the  MPC’s 
prediction about future rates.  The difference is that, to the extent that the market rate curve embodies 
the market’s guess about where the MPC will take rates, forecasts predicated on the market rate are 
more easily interpreted as a comment on that view. 
So how much significance should be read into our change of conditioning assumption? Did the switch 
to market rates represent a tentative step towards providing more guidance on the future direction of 
policy? 
The fact that interest rates were historically very low in 2003 and early 2004 has some bearing on the 
matter.  Many  academics,  notably  Lars  Svensson,  have  argued  persuasively  that  the  use  of  an 
unrealistic conditioning assumption makes it more difficult for the public to interpret the MPC’s reading 
of the economic outlook.  As Charlie Bean has pointed out,17 this is certainly true if interest rates are 
some  way  off  ‘normal’  levels  or  if  for  other  reasons,  they  are  expected  to  increase  or  decrease 
substantially over the forecast horizon – and the longer the time horizon of the forecast, the more force 
this argument has.  
Our  decision  to  shift  the  focus  of  the  presentation  to  market  rates  was  coupled  with  a  decision  to 
publish forecasts for three years, rather than two, as was previously the case. This did not reflect a 
change in policy horizon – we are required to meet our 2% target ‘at all times’. But it did provide useful 
context for interpreting the gradient of inflation forecasts at the two year horizon, and hence a clearer 
indication of future policy, if the economy evolves in line with the central projection.  
The shift to using a market rate assumption was a very modest step towards greater transparency. At 
a  technical  level,  it  is  a  non  trivial  task  to  translate  any  market  rate  yield  curve  into  a  conventional 
forecasting assumption which is a genuine reflection of market expectations of future official interest 
rates.18  And markets are themselves uncertain about the path of future rates so we publish a fan chart 
for market interest rate to help quantify that uncertainty, based on options prices. 
There is a big difference between a conditioning assumption and a commitment, not least because 
there  is  a  big  gap  between  anyone’s  current  guess  at  where  rates  might  need  to  go  to  meet  the 
inflation target, conditional on the data available at any point in time, and where the MPC will actually 
take rates given the information it may have in the future. But the MPC was conscious of the risk of 
misinterpretation, so the transition was made gradually – with the Governor reflecting on the market 
curve  in  his  remarks  at  the  February  and  May  Inflation  Report  press  conferences,  and  the  MPC 
referring to the market curve in the minutes during the spring.  By the time the switch was introduced 
in  the  August  Inflation  Report,  MPC  and  markets  understood  the  nature  of  the  conditioning 
assumption, and the change itself was seen as the marginal improvement that it is.   
                                                      
16   See Inflation Report August 2004 pp 42-43. 
17   Bean, C (2004) ‘Some current issues in UK Monetary Policy’ Bank of England Quarterly Bulletin Autumn 2004. 
18   For further details on this issue see Brooke, M, Cooper, N and Scholtes, C (2000) ‘Inferring market interest rates from 
money market rates’ Bank of England Quarterly Bulletin November 2000. For further information and data, please see the 
Bank of England website www.bankofengland.co.uk.  
BIS Review 17/2005 
 9
 
Chart 4.  Market beliefs about future interest rates 
– Inflation Report February 2005 
    
Different  inflation  targeting  central  banks  have  evolved  their  own  ways  of  communicating.    At  one 
extreme,  the  Governor  of  the  Reserve  Bank  of  New  Zealand  publishes  his  own  forecast  of  future 
interest  rates  –  though  he  is  the  sole  decision  taker  in  that  regime.  And  at  the  Norges  Bank,  staff 
produce material that explicitly sets out possible strategies for interest rate decisions in the form of a 
range  of  interest  rates  for  the  next  3-4  months,  and  invite  the  interest  rate  setting  committee  to 
endorse them, and provide a commentary on market expectations of future interest rates. As Charles 
Goodhart has argued, it is difficult, as a practical matter, to imagine a committee of nine individually 
accountable experts doing that.  
Institutional  and  political  arrangements  matter.  What  works  in  one  environment  may  not  work 
elsewhere.  And  central  banks  need  to  employ  consistent  modes  of  communication  and  language  if 
they are to be well understood. Abrupt changes in what is communicated, and how, always carry risks 
of  confusion.  But  even  the  best  designed  system  needs  to  evolve.  Greater  transparency  involves 
learning  both  by  policymakers  and  by  those  who  seek  to  interpret  their  actions.  The  degree  of 
monetary policy transparency in the UK now would have been regarded as quite unthinkable fifteen 
years ago. I see no reason to suppose that we have reached the end of the road yet. 
Conclusions 
Published  forecasts  have  come  to  play  a  key  role  in  formulating  and  communicating  interest  rate 
decisions within the UK approach to inflation targeting. The strength of this approach is that – flawed 
and  inadequate  as  all  projections  inevitably  are  –  a  good  forecast  paints  a  picture  that  is  worth  a 
thousand words. And that counts, both when it comes to organising the debate between nine experts, 
and when it comes to explaining the basis of policy to a non expert public. 
But forecasts are highly fallible, so our forecast centred approach to inflation targeting has gone hand 
in  hand  with  a  determined  effort  to  illustrate  the  wide  range  of  uncertainties  around  any  central 
projection  and  a  systematic  attempt  to  factor  the  Committee’s  own  judgements  about  the  risks  into 
decision taking. That, for me, is a key reason for resisting recent calls by the IMF and others for the 
Bank to ‘publish numerical projections for a broader range of key variables’. Detail is seductive – but it 
can also be highly misleading, and a committee that spent its time debating the details of the forecast 
rather than using it as a tool to address big picture issues would be at risk of losing its way. 
Forecasts are indispensable – but they should be handled with care. 
10 
 BIS Review 17/2005
Table 2.  Interest rate surprises
A. Are rates changes evenly spread over the months of the year?
B. Are rates changes expected to be spread 
     evenly over the months of the year?
Rate changes
IR months
non-IR months
Whole period
1997-2000
2001-present
15
6
9
14
10
4
χ2 statistic
4.41**
0.13
7.54***
Expected rate changes
IR months
non-IR months
Whole period
1997-2000
2001-present
14
6
8
8
5
3
χ2 statistic
9.09***
2.23
7.68***
C. Are interest rate surprises getting smaller?
D. Are interest rate surprises larger in Inflation Report  months?
Observations
Reuters measure:
1998-2000
2001-present
Difference
LIBOR measure:
1997-2000
2001-present
Difference
30
50
43
50
Average magnitude 
of rate 'surprise' 
(bp)
11
7.6
-3.3**
5.4
3.6
-1.8*
Average of 'surprise' variable (bp)
IR months
Other months
Difference
Reuters measure
Whole period
1998-2000
2001-present
LIBOR measure 
Whole period
1997-2000
2001-present
10.6
12.6
9.5
5.9
5.5
6.3
7.9
10.0
6.6
3.7
5.3
2.2
+2.7*
+2.6
+2.8
+2.3**
+0.2
+4.0**
E. Market reactions in Inflation Report  months
Average magnitude of 'surprise' / market reaction (bp)
Policy decision
Inflation Report 
publication
MPC minutes 
publication
Difference between 
reaction to policy 
decision and IR 
publication
Difference between 
reaction to policy 
decision and MPC 
minutes publication
Observations
LIBOR measure:
Whole period
1997-2000
2001-present
Difference
5.9
5.5
6.3
0.7
3.0
3.4
2.7
-0.8
2.8
2.4
3.1
0.7
+2.9**
+2.1
+3.6**
+3.1**
+3.1**
+3.2**
31
14
17
Notes:
Tests are for significance based on t-test for difference between two sample means, except for Panel (A) and (B), which is a test for whether
rate changes are distributed 1/3 in IR months and 2/3 in other months.  The critical values for Panel (A) and (B) are derived from on Monte Carlo simulations.
Excludes the special MPC meeting following 11 September 2001.
*** significantly higher/lower than zero at 1% level, ** 5% level, * 10% level (one-tailed tests)
Libor measure: based on the change in implied 3-month Libor forward rate derived by linear interpolation of adjecent short sterling futures contracts.
Changes in implied forward rates normally taken from: 11:30am to 12:30pm for interest rate announcements; 
10:00am to 12:00pm for IR publication; and 9:00am to 10:30am for minutes publication.
Reuters measure: difference between the actual repo rate change and the mean expectation of the economists
 BIS Review 17/2005 
 11
